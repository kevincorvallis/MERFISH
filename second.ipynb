{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# python3 -m pip install -q observable_jupyter==0.1.10\n",
    "%%capture\n",
    "# Installation and Imports \n",
    "python -m pip install -q fsspec\n",
    "python -m pip install -q gcsfs\n",
    "\n",
    "python -m pip install -q tifffile\n",
    "python -m pip install -q pandas\n",
    "python -m pip install -q opencv-python\n",
    "python -m pip install -q h5py\n",
    "python -m pip install -q matplotlib\n",
    "\n",
    "\n",
    "python -m pip install -q observable_jupyter==0.1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial Imports\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from observable_jupyter import embed\n",
    "from math import cos, sin\n",
    "\n",
    "\n",
    "\n",
    "import tifffile\n",
    "import cv2\n",
    "import h5py\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Data\n",
    "base_path = '/Volumes/Samsung_T5/5c/'\n",
    "region = 'region_0/'\n",
    "slice_num = 2\n",
    "replicate_num = 1\n",
    "\n",
    "# dataset_name = 'Slice' + str(slice_num) + '/Replicate' + str(replicate_num) + '/'\n",
    "# dataset_suffix = '_S' + str(slice_num) + 'R' + str(replicate_num)\n",
    "z_index_number = 0\n",
    "fov = 783\n",
    "\n",
    "# load transformation matrix \n",
    "# This is used to transfer from global coordinates (the coordinates of transcripts \n",
    "# and cells across the sample) to mosaic coordinates (used for the large TIF image files).\n",
    "\n",
    "filename = base_path + region + 'images/micron_to_mosaic_pixel_transform.csv'\n",
    "transformation_matrix = pd.read_csv(filename, header=None, sep=' ').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# load transformation matrix \n",
    "# This is used to transfer from global coordinates (the coordinates of transcripts \n",
    "# and cells across the sample) to mosaic coordinates (used for the large TIF image files).\n",
    "# filename = base_path + dataset_name + 'images/micron_to_mosaic_pixel_transform.csv'\n",
    "# transformation_matrix = pd.read_csv(filename, header=None, sep=' ').values\n",
    "\n",
    "# load cell boundaries for a single fov\n",
    "fov = 0\n",
    "\n",
    "filename = base_path + region + \"cell_boundaries/\" +'feature_data_' +  str(fov) + '.hdf5'\n",
    "print(filename)\n",
    "cellBoundaries = h5py.File(filename)\n",
    "meta_cell = pd.read_csv(base_path + region + 'cell_metadata' + '.csv', index_col=0)\n",
    "meta_cell = meta_cell[meta_cell.fov == fov]\n",
    "\n",
    "z_index = 'zIndex_' + str(z_index_number)\n",
    "# collect boundaries in fov \n",
    "currentCells = []\n",
    "for inst_cell in meta_cell.index.tolist():\n",
    "    try:\n",
    "        # cellBoundaries['featuredata'][inst_cell][z_index]['p_0']['coordinates'][0]\n",
    "        temp = cellBoundaries['featuredata'][inst_cell][z_index]['p_0']['coordinates'][0]\n",
    "        boundaryPolygon = np.ones((temp.shape[0], temp.shape[1]+1))\n",
    "        boundaryPolygon[:, :-1] = temp\n",
    "        transformedBoundary = np.matmul(transformation_matrix, np.transpose(boundaryPolygon))[:-1]\n",
    "        currentCells.append(transformedBoundary)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "minCoord = np.min([np.min(x, axis=1) for x in currentCells], axis=0).astype(int)\n",
    "maxCoord = np.max([np.max(x, axis=1) for x in currentCells], axis=0).astype(int)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transcript data - this takes about 25min\n",
    "transcripts = pd.read_csv(base_path + region + 'detected_transcripts' + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts['gene'].value_counts().head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gene colors\n",
    "# colors from https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "gene_colors = {\n",
    "    'Slc1a2': 'teal',\n",
    "    'Map1b': 'orangered',\n",
    "    'Dpysl2': 'indigo',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# code for compressing data for visuals\n",
    "import zlib, json, base64\n",
    "def json_zip(j):\n",
    "    zip_json_string = base64.b64encode(\n",
    "        zlib.compress(\n",
    "            json.dumps(j).encode('utf-8')\n",
    "        )\n",
    "    ).decode('ascii')\n",
    "    return zip_json_string\n",
    "\n",
    "# process data for interactive visual\n",
    "keep_genes = gene_colors.keys()\n",
    "transcripts_keep = transcripts[transcripts.gene.isin(keep_genes)]\n",
    "transcripts_keep['-global_y'] = -transcripts_keep['global_y']\n",
    "\n",
    "# rotate the mouse brain to the upright position\n",
    "theta = np.deg2rad(-195) # -15\n",
    "rot = np.array([[cos(theta), -sin(theta)], [sin(theta), cos(theta)]])\n",
    "transcripts_keep[['global_x', '-global_y']] = transcripts_keep[['global_x', '-global_y']].dot(rot)\n",
    "\n",
    "transcripts_keep['name'] = transcripts_keep['gene']\n",
    "transcripts_keep['position'] = transcripts_keep[['global_x', '-global_y']].round(2).values.tolist()\n",
    "transcripts_viz = deepcopy(transcripts_keep[['name', 'position']])\n",
    "transcripts_string_zip = json_zip(transcripts_viz.to_dict('records'))\n",
    "\n",
    "transcripts_inputs = {\n",
    "          'zip_string': transcripts_string_zip,\n",
    "          'radius_min_pixels': 1.0,\n",
    "          'height': 800, \n",
    "          'gene_colors': gene_colors, \n",
    "          'min_zoom': -6\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed('@vizgen/gene-transcripts-jupyter-v0-2-0', cells=['dashboard'], inputs=transcripts_inputs, display_logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bda69861a0de96b982cd51b23c6f44e92e9b007651abcd3b17983d498a1ed930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
